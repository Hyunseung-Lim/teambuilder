import { ChatOpenAI } from "@langchain/openai";
import { HumanMessage, SystemMessage } from "@langchain/core/messages";
import {
  generateIdeaPrompt,
  evaluateIdeaPrompt,
  feedbackPrompt,
  requestPrompt,
  planNextActionPrompt,
  preIdeationPrompt,
  newIdeationPrompt,
  updateIdeationPrompt,
  preEvaluationPrompt,
  executeEvaluationPrompt,
  alreadyEvaluatedResponsePrompt,
  createPlanningPrompt,
  preRequestPrompt,
  executeRequestPrompt,
} from "@/core/prompts";
import { AgentMemory } from "@/lib/types";
import OpenAI from "openai";

if (!process.env.OPENAI_API_KEY) {
  throw new Error("OPENAI_API_KEY is not set in the environment variables.");
}

const llm = new ChatOpenAI({
  model: "gpt-4o",
  temperature: 0.5,
});

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

async function getJsonResponse(prompt: string, agentProfile?: any) {
  const messages = [];

  // ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¡œ AI ì—ì´ì „íŠ¸ ë°ëª¨ê·¸ë˜í”½ ì •ë³´ ì¶”ê°€
  if (agentProfile) {
    console.log("ì›ë³¸ agentProfile:", JSON.stringify(agentProfile, null, 2));

    // í•„ë“œëª… ë§¤í•‘ (professional -> occupation)
    const occupation =
      agentProfile.occupation || agentProfile.professional || "professional";

    let systemPrompt = `You are ${agentProfile.name || "Agent"}, a ${
      agentProfile.age || "30"
    }-year-old ${occupation}.`;

    if (agentProfile.description) {
      systemPrompt += ` ${agentProfile.description}`;
    }

    if (agentProfile.personality) {
      const personalityText = Array.isArray(agentProfile.personality)
        ? agentProfile.personality.join(", ")
        : String(agentProfile.personality);
      systemPrompt += ` Your personality: ${personalityText}.`;
    }

    if (agentProfile.skills) {
      const skillsText = Array.isArray(agentProfile.skills)
        ? agentProfile.skills.join(", ")
        : String(agentProfile.skills);
      systemPrompt += ` Your skills: ${skillsText}.`;
    }

    systemPrompt +=
      " Generate ideas that reflect your unique background, expertise, and perspective. Always respond in Korean.";

    console.log("ìµœì¢… ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸:", systemPrompt);
    messages.push(new SystemMessage(systemPrompt));
  }

  console.log("ìµœì¢… ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸:", prompt);
  messages.push(new HumanMessage(prompt));

  try {
    const response = await llm.invoke(messages);
    const rawResponse = response.content;

    console.log("=== LLM ì‘ë‹µ ë¡œê·¸ ===");
    console.log("ì›ë³¸ LLM ì‘ë‹µ:", rawResponse);
    console.log("==================");

    if (!rawResponse) {
      throw new Error("OpenAI returned an empty response.");
    }

    // JSON ë§ˆí¬ë‹¤ìš´ ë¸”ë¡ ì œê±°
    const cleanedResponse = rawResponse
      .toString()
      .replace(/```json\n?|```/g, "")
      .trim();

    const parsedResponse = JSON.parse(cleanedResponse);
    console.log("íŒŒì‹±ëœ JSON ì‘ë‹µ:", JSON.stringify(parsedResponse, null, 2));
    return parsedResponse;
  } catch (error) {
    console.error("LLM ì‘ë‹µ ì²˜ë¦¬ ì˜¤ë¥˜:", error);
    // ì˜¤ë¥˜ë¥¼ ê·¸ëŒ€ë¡œ ì „ë‹¬í•˜ì—¬ í˜¸ì¶œí•œ ìª½ì—ì„œ ì²˜ë¦¬í•˜ë„ë¡ í•¨
    throw error;
  }
}

// --- Action Functions ---

export async function generateIdeaAction(
  context?: string,
  userProfile?: any,
  existingIdeas?: Array<{
    ideaNumber: number;
    authorName: string;
    object: string;
    function: string;
  }>
) {
  // ê¸°ì¡´ ì•„ì´ë””ì–´ê°€ ìˆìœ¼ë©´ í”„ë¡¬í”„íŠ¸ì— í¬í•¨
  let enhancedContext = context || "Carbon Emission Reduction";

  if (existingIdeas && existingIdeas.length > 0) {
    const existingIdeasText = existingIdeas
      .map(
        (idea) =>
          `${idea.ideaNumber}. "${idea.object}" (ì‘ì„±ì: ${idea.authorName}) - ${idea.function}`
      )
      .join("\n");

    enhancedContext += `\n\nê¸°ì¡´ì— ìƒì„±ëœ ì•„ì´ë””ì–´ë“¤:\n${existingIdeasText}\n\nìœ„ ì•„ì´ë””ì–´ë“¤ê³¼ ì¤‘ë³µë˜ì§€ ì•ŠëŠ” ìƒˆë¡œìš´ ê´€ì ì˜ ì•„ì´ë””ì–´ë¥¼ ìƒì„±í•˜ì„¸ìš”.`;
  }

  const prompt = generateIdeaPrompt(enhancedContext, userProfile);
  return getJsonResponse(prompt, userProfile);
}

export async function evaluateIdeaAction(idea: any, context?: string) {
  const prompt = evaluateIdeaPrompt(idea, context);
  return getJsonResponse(prompt);
}

export async function feedbackAction(target: string, context: string) {
  const prompt = feedbackPrompt(target, context);
  return getJsonResponse(prompt);
}

// ìƒˆë¡œìš´ êµ¬ì²´ì ì¸ í”¼ë“œë°± í•¨ìˆ˜
export async function giveFeedbackOnIdea(
  targetIdea: any,
  userProfile: any,
  teamContext: any
) {
  const ideaAuthor =
    targetIdea.author === "ë‚˜"
      ? "ë‚˜"
      : (() => {
          const member = teamContext.teamMembers.find(
            (m: any) => m.agentId === targetIdea.author
          );
          return member?.name || targetIdea.author;
        })();

  const prompt = `ë‹¹ì‹ ì€ ${userProfile.name}ì…ë‹ˆë‹¤. íŒ€ ì•„ì´ë””ì–´ ì„¸ì…˜ì—ì„œ ë‹¤ìŒ ì•„ì´ë””ì–´ì— ëŒ€í•´ êµ¬ì–´ì²´ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ í”¼ë“œë°±ì„ ì£¼ì„¸ìš”.

í‰ê°€í•  ì•„ì´ë””ì–´:
- ì œëª©: ${targetIdea.content.object}
- ê¸°ëŠ¥: ${targetIdea.content.function}
- ì‘ì„±ì: ${ideaAuthor}

ì£¼ì œ: ${teamContext.topic}

í”¼ë“œë°± ê°€ì´ë“œë¼ì¸:
1. êµ¬ì–´ì²´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„± (ì˜ˆ: "ì´ ì•„ì´ë””ì–´ ì •ë§ ì¢‹ë„¤ìš”!", "~í•˜ë©´ ì–´ë–¨ê¹Œìš”?")
2. êµ¬ì²´ì ì¸ ê°œì„ ì ì´ë‚˜ í™•ì¥ ì•„ì´ë””ì–´ ì œì‹œ
3. ê¸ì •ì ì´ë©´ì„œë„ ê±´ì„¤ì ì¸ í†¤ ìœ ì§€
4. ì‘ì„±ìë¥¼ ì§ì ‘ ì–¸ê¸‰í•˜ë©° ëŒ€í™”í•˜ë“¯ ì‘ì„±
5. 200ì ë‚´ì™¸ë¡œ ê°„ê²°í•˜ê²Œ

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{
  "feedback": "êµ¬ì–´ì²´ë¡œ ì‘ì„±ëœ ìì—°ìŠ¤ëŸ¬ìš´ í”¼ë“œë°± ë‚´ìš©"
}`;

  return getJsonResponse(prompt, userProfile);
}

export async function requestAction(target: string, context: string) {
  const prompt = requestPrompt(target, context);
  return getJsonResponse(prompt);
}

// --- Planning Function ---

export async function planNextAction(
  userProfile: any,
  teamContext: {
    teamName: string;
    topic: string;
    currentIdeasCount: number;
    recentMessages: any[];
    teamMembers: string[];
    existingIdeas: Array<{
      ideaNumber: number;
      authorName: string;
      object: string;
      function: string;
    }>;
  }
): Promise<{
  action:
    | "generate_idea"
    | "evaluate_idea"
    | "give_feedback"
    | "make_request"
    | "wait";
  reasoning: string;
  target?: string;
}> {
  try {
    const prompt = createPlanningPrompt(userProfile, teamContext);

    const completion = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [
        {
          role: "user",
          content: prompt,
        },
      ],
      temperature: 0.8, // ì•½ê°„ì˜ ì°½ì˜ì„± í—ˆìš©
      max_tokens: 200,
    });

    const response = completion.choices[0]?.message?.content?.trim();
    if (!response) {
      throw new Error("No response from OpenAI");
    }

    // JSON íŒŒì‹±
    const cleanedResponse = response.replace(/```json\n?|```/g, "").trim();

    const planResult = JSON.parse(cleanedResponse);

    // ìœ íš¨ì„± ê²€ì‚¬
    const validActions = [
      "generate_idea",
      "evaluate_idea",
      "give_feedback",
      "make_request",
      "wait",
    ];
    if (!validActions.includes(planResult.action)) {
      throw new Error(`Invalid action: ${planResult.action}`);
    }

    console.log(`ğŸ§  ${userProfile.name} ê³„íš ê²°ê³¼:`, planResult);

    return {
      action: planResult.action,
      reasoning: planResult.reasoning || "No reasoning provided",
      target: planResult.target,
    };
  } catch (error) {
    console.error("Planning ì‹¤íŒ¨:", error);

    // ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í–‰ë™ (ì—­í• ì— ë”°ë¼)
    if (userProfile.roles?.includes("ì•„ì´ë””ì–´ ìƒì„±í•˜ê¸°")) {
      return {
        action: "generate_idea",
        reasoning:
          "Default action due to planning error - generating idea based on role",
      };
    } else if (
      userProfile.roles?.includes("ì•„ì´ë””ì–´ í‰ê°€í•˜ê¸°") &&
      teamContext.currentIdeasCount > 0
    ) {
      return {
        action: "evaluate_idea",
        reasoning:
          "Default action due to planning error - evaluating ideas based on role",
      };
    } else if (userProfile.roles?.includes("ìš”ì²­í•˜ê¸°")) {
      return {
        action: "make_request",
        reasoning:
          "Default action due to planning error - making request based on role",
      };
    } else {
      return {
        action: "wait",
        reasoning: "Default action due to planning error - waiting",
      };
    }
  }
}

// --- New 2-Stage Ideation Action Functions ---

export async function preIdeationAction(
  requestMessage: string,
  ideaList: {
    ideaNumber: number;
    authorName: string;
    object: string;
    function: string;
  }[],
  userProfile?: any,
  memory?: AgentMemory
) {
  const prompt = preIdeationPrompt(requestMessage, ideaList, memory);
  return getJsonResponse(prompt, userProfile);
}

export async function executeIdeationAction(
  decision: "New" | "Update",
  ideationStrategy: string,
  topic: string,
  referenceIdea?: any,
  userProfile?: any,
  memory?: AgentMemory
) {
  let prompt;
  if (decision === "New") {
    prompt = newIdeationPrompt(ideationStrategy, topic, memory);
  } else {
    if (!referenceIdea) {
      throw new Error("Reference idea is required for 'Update' decision.");
    }
    prompt = updateIdeationPrompt(
      referenceIdea,
      ideationStrategy,
      topic,
      memory
    );
  }
  return getJsonResponse(prompt, userProfile);
}

// --- New 2-Stage Evaluation Action Functions ---

export async function preEvaluationAction(
  requestMessage: string,
  ideaList: {
    ideaNumber: number;
    authorName: string;
    object: string;
    function: string;
  }[],
  userProfile?: any,
  memory?: AgentMemory
) {
  const prompt = preEvaluationPrompt(requestMessage, ideaList, memory);
  return getJsonResponse(prompt, userProfile);
}

export async function executeEvaluationAction(
  selectedIdea: any,
  evaluationStrategy: string,
  userProfile?: any,
  memory?: AgentMemory
) {
  const prompt = executeEvaluationPrompt(
    selectedIdea,
    evaluationStrategy,
    memory
  );
  return getJsonResponse(prompt, userProfile);
}

// --- Function for generating responses when already evaluated ---

export async function generateAlreadyEvaluatedResponse(
  requesterName: string,
  selectedIdea: any,
  previousEvaluation: any,
  relationshipType: string | null,
  userProfile?: any
) {
  const prompt = alreadyEvaluatedResponsePrompt(
    requesterName,
    selectedIdea,
    previousEvaluation,
    relationshipType,
    userProfile
  );
  return getJsonResponse(prompt, userProfile);
}

// New request-related functions

export async function preRequestAction(
  triggerContext: string,
  teamMembers: Array<{
    name: string;
    roles: string[];
    isUser: boolean;
    agentId?: string;
  }>,
  currentIdeas: Array<{
    ideaNumber: number;
    authorName: string;
    object: string;
    function: string;
  }>,
  userProfile?: any,
  memory?: AgentMemory
) {
  const prompt = preRequestPrompt(
    triggerContext,
    teamMembers,
    currentIdeas,
    memory
  );
  return getJsonResponse(prompt, userProfile);
}

export async function executeRequestAction(
  targetMember: string,
  requestType: string,
  requestStrategy: string,
  contextToProvide: string,
  targetMemberRoles: string[],
  relationshipType?: string,
  userProfile?: any,
  memory?: AgentMemory,
  originalRequest?: string,
  originalRequester?: string
) {
  const prompt = executeRequestPrompt(
    targetMember,
    requestType,
    requestStrategy,
    contextToProvide,
    targetMemberRoles,
    relationshipType,
    memory,
    originalRequest,
    originalRequester
  );
  return getJsonResponse(prompt, userProfile);
}

// Unified request function for both users and AI agents
export async function makeRequestAction(
  triggerContext: string,
  teamMembers: Array<{
    name: string;
    roles: string[];
    isUser: boolean;
    agentId?: string;
  }>,
  currentIdeas: Array<{
    ideaNumber: number;
    authorName: string;
    object: string;
    function: string;
  }>,
  userProfile?: any,
  memory?: AgentMemory,
  originalRequest?: string,
  originalRequester?: string
) {
  // Step 1: Analyze request
  const requestAnalysis = await preRequestAction(
    triggerContext,
    teamMembers,
    currentIdeas,
    userProfile,
    memory
  );

  // Step 2: Execute request
  const targetMemberInfo = teamMembers.find(
    (member) => member.name === requestAnalysis.targetMember
  );

  if (!targetMemberInfo) {
    throw new Error(`Target member ${requestAnalysis.targetMember} not found`);
  }

  const requestMessage = await executeRequestAction(
    requestAnalysis.targetMember,
    requestAnalysis.requestType,
    requestAnalysis.requestStrategy,
    requestAnalysis.contextToProvide,
    targetMemberInfo.roles,
    undefined, // No relationship info for users
    userProfile,
    memory,
    originalRequest,
    originalRequester
  );

  return {
    analysis: requestAnalysis,
    message: requestMessage,
  };
}
